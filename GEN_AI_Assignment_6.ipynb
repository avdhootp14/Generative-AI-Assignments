{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c8edf7f83ea04314a129e45dbba543f0"
          ]
        },
        "id": "XJVuzGDxV545",
        "outputId": "d43d7aaa-3c0a-407c-d4a1-5309f52832d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8edf7f83ea04314a129e45dbba543f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from diffusers import AutoPipelineForText2Image\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 766,
          "referenced_widgets": [
            "01dce47b4a96409185f3294b1248d4ed",
            "c54fe105d9b34adc97442932a71677c6",
            "969d327075c749c8a2e8595f36f715cd",
            "e063b0b32d4e4bc9acaca25c19088a03",
            "3f8b3637fc0b470ca4c4e9d077f78652",
            "88f0d901ef5c44d9bf2cfee68119f016",
            "ed790777501849689cdc3304df3f63cd",
            "4adbf4d7cf93466c8e898246f50b2fed",
            "8cfc3eab9c1441b2834b285c67f444ba",
            "52361501878f4523aded049de5896aa2",
            "921d2d2c0bcd4bdbbed61b1676a789e3",
            "2b9f120ad6f948c8af2f2e6a5e70e58b",
            "486ef220387443d3bda810fe9a6d1e59",
            "9fbd601fd9ba4977a1b175d6ae1842f7",
            "060ba302667b4b45a654e12685bf772d",
            "b3fd691c54c6491fb9eed63d2a465a92",
            "64504cd8bab24afabd2989a53441b183",
            "91d97fc6f44841a6af2f560841cea0d8",
            "ba8f537578a947e4938ba94dd1a31a5c"
          ]
        },
        "id": "08NzXLpcUMD6",
        "outputId": "f303afe3-ffd3-43ea-b114-f765d1d74eb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01dce47b4a96409185f3294b1248d4ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_index.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c54fe105d9b34adc97442932a71677c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "969d327075c749c8a2e8595f36f715cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.fp16.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e063b0b32d4e4bc9acaca25c19088a03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f8b3637fc0b470ca4c4e9d077f78652",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88f0d901ef5c44d9bf2cfee68119f016",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/575 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed790777501849689cdc3304df3f63cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4adbf4d7cf93466c8e898246f50b2fed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cfc3eab9c1441b2834b285c67f444ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52361501878f4523aded049de5896aa2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "921d2d2c0bcd4bdbbed61b1676a789e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b9f120ad6f948c8af2f2e6a5e70e58b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "486ef220387443d3bda810fe9a6d1e59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fbd601fd9ba4977a1b175d6ae1842f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "060ba302667b4b45a654e12685bf772d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3fd691c54c6491fb9eed63d2a465a92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64504cd8bab24afabd2989a53441b183",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "diffusion_pytorch_model.fp16.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91d97fc6f44841a6af2f560841cea0d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba8f537578a947e4938ba94dd1a31a5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "# Load the pipeline\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ")\n",
        "pipe.to(\"cuda\")\n",
        "\n",
        "# Define prompt\n",
        "prompt = \"A Robot Driving a car with his friends\"\n",
        "\n",
        "# Generate image\n",
        "image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]\n",
        "\n",
        "# Save the image\n",
        "image.save(\"generated_image.png\")\n",
        "\n",
        "print(\"Image saved as generated_image.png\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}